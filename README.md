# 한밭대학교 SW중심대학 산학연계프로젝트 - 모바일 로봇의 자율 주행을 위한 장애물 탐지 및 회피 판단 알고리즘 개발
## **팀 구성**
### 지도교수
 - 이현빈 교수님
### 기업체 
 - 김곤민 대표
### 참여학생
 - 30231216 이보석 
 - 20217137 송찬호
 - 20191742 유태원
## Project Background
- ### 필요성
  **농업 및 축산 환경 변화**: 농업 인구 감소와 노동력 부족 문제로 인해 스마트팜 기술의 필요성이 점점 대두되고 있음. 스마트팜 기술은 생산성 향상과 자원 최적화를 가능하게 하며, 다양한 작업을 자동화할 수 있는 기술로 주목받고 있음.  
  **지속 가능한 관리 시스템 필요**: 특히 양돈 농장에서 사용되는 기존 CCTV 시스템은 분뇨로 인한 잦은 교체와 유지보수 비용 문제로 접근성이 낮음. 이에 따라 더 경제적이고 효과적인 대체 시스템으로 모바일 로봇 기반 솔루션 오구.  
  **정확한 데이터 수집 및 환경 모니터링**: 육돈의 행동 분석과 환경 관리 데이터를 실시간으로 수집하고 분석할 수 있는 시스템이 필요함. 이는 정밀 축산 관리와 자동화된 작업을 통해 효율성을 높이고, 질병 확산 방지 및 건강 관리 지원.  
 
- ### 기존 해결책의 문제점
  **CCTV 기반 시스템의 한계**: 유지보수 비용이 높고, 분뇨로 인해 자주 교체가 필요하며, 지속적인 모니터링이 어려움. 야간 및 주말 등 관리 인력이 부재한 시간에 모니터링 공백이 발생함.  
  **센서 데이터의 부정확성**: IMU의 누적 오차 및 엔코더의 슬립 현상으로 인해 이동체의 위치 추정이 정확하지 못한 경우가 많음. 이러한 문제는 칼만 필터와 같은 센서 퓨전 알고리즘을 통해 개선해야 하지만 기존 시스템에서 충분히 구현되지 않음.  
  **장애물 회피의 비효율성**: 기존 기술은 다양한 장애물 크기와 높이에 따라 등판 여부를 정확히 판단하지 못하며, 새로운 경로 생성 및 회피 주행에도 어려움이 있음.  
  **시스템 통합의 부재**: 농업 환경에 적합한 로봇 플랫폼 개발이 제한적이며, 기존 장비와의 통합 및 확장이 용이하지 않음.  
  
## System Design
  - ### System Requirements
    **1. 하드웨어 요구사항**
        로봇 하드웨어: 모터 제어기, IMU(관성측정장치), 엔코더가 장착된 이동 로봇. 컬러 및 깊이 프레임을 수집할 수 있는 Realsense D455 카메라.  
        ROS 노드 실행 및 딥러닝 추론을 처리할 수 있는 컴퓨팅 장치(예: Jetson Xavier 또는 NVIDIA GPU 지원 SBC).  
        센서 및 액추에이터: PWM 또는 기타 신호로 제어 가능한 모터. 거리와 방향을 감지할 수 있는 센서(IMU 및 엔코더).  
    
    **2. 소프트웨어 요구사항**
      운영 체제:
       ROS와 호환되는 Linux 기반 운영 체제(예: Ubuntu 20.04, ROS Noetic 사용)  
    
      ROS 노드:
       control_node: PID 제어를 통해 로봇의 이동을 제어.  
       segpredict_node: 카메라 프레임을 기반으로 세그멘테이션 및 목표 지점 예측 수행.  
       사용되는 ROS 토픽: /cmd_vel: 속도 명령 퍼블리시. /odom: 오도메트리 데이터 구독. /center_point: 내비게이션 목표 지점을 퍼블리시. /request_next_target: 다음 목표 요청.  
    
      **라이브러리**:
       rospy: Python에서 ROS 통합.  
       cv2(OpenCV): 이미지 처리 및 시각화.  
       numpy: 수치 계산.  
       torch(PyTorch): Semantic Segmentation 추론.  
       pyrealsense2: Intel RealSense 카메라와 연동.  
       ROS 메시지 타입: geometry_msgs/Twist, std_msgs/Bool 및 String, nav_msgs/Odometry  
    
     **3. 성능 요구사항**
      실시간 이미지 처리 및 세그멘테이션 프레임 속도: 30 FPS.  
      내비게이션 정밀도: 위치 정확도: ±0.1미터. 방향 정확도: ±5도.
    
     **4. 기능 요구사항**
     제어 시스템: PID 제어를 통해 로봇의 부드럽고 정밀한 이동 가능. 목표 지점 자동 탐지 및 도달 후 재조정. 목표 도달 시 정지 및 초기화 기능.  
     추론 시스템: RGB 및 Depth 프레임의 실시간 처리. 세그멘테이션된 이동 가능 영역의 중심점 계산을 위한 볼록 결함 분석.  
     통신: 센서 데이터 및 명령을 위한 ROS 노드 간 효율적인 토픽 기반 통신.  
    
## Case Study
  - ### Description
    **1. 프로젝트 배경**
     문제 정의: 농업 및 축산업 환경에서 지속 가능한 모니터링 시스템은 노동력 감소와 기존 기술의 한계를 해결하기 위해 필요함. 특히, 양돈 농장에서 사용되는 기존 CCTV 시스템은 높은 유지보수 비용과 분뇨로 인한 잦은 교체, 야간이나 관리 인력이 부재한 시간에 실시간 모니터링의 어려움의 문제가 있음.  
     기존 시스템의 한계: 기존 로봇 시스템은 IMU와 엔코더 데이터를 활용하지만, 누적 오차 및 슬립 문제로 인해 정확도가 낮음. 또한, 장애물 회피 및 경로 생성 알고리즘은 복잡한 환경에서 안정성을 보장하지 못함.  
     
    **2. 목표**
     장애물 탐지 및 회피를 위한 실시간 RGB-D 세그멘테이션 알고리즘 구현. PID 제어를 통해 이동 경로를 안정적으로 유지하며 목표 지점까지 이동. 센서 데이터를 활용하여 로봇의 위치 및 상태를 정확히 추정.  
     
    **3. 시스템 설계 및 구현**
     본 시스템은 두 개의 주요 ROS 노드로 구성.  
     control_node: 로봇의 PID 기반 이동 제어. segpredict_node: RGB-D 카메라로부터 실시간 세그멘테이션 수행.  
     
     **사용된 기술 및 알고리즘**
     센서 퓨전: Intel RealSense RGB-D 카메라를 활용한 컬러 및 깊이 정보를 수집하여 장애물 탐지. IMU와 엔코더를 활용한 위치 및 방향 추적.  
     세그멘테이션 알고리즘: PIDNet 기반 딥러닝 모델 사용. RGB-D 데이터를 입력으로 받아 이동 가능 영역, 이동 불가능 영역, 장애물을 세그멘테이션을 통해 추론.  
     볼록 결함(Convexity Defect)을 활용하여 이동 경로의 중심점 계산.  
     PID 제어: 거리와 각도 오차를 계산하여 선형 및 각속도 제어. 칼만 필터를 사용해 센서 데이터를 융합하고 위치 추정의 정확도 향상.  
     
     **주요 구현 사항**
     control_node: /cmd_vel 토픽을 통해 로봇의 속도 명령 발행. /odom 데이터를 활용하여 로봇의 현재 위치 및 방향 계산. 목표 도달 시 /request_next_target 토픽을 통해 다음 목표 요청.  
     segpredict_node: 실시간 프레임 처리 속도: 30 FPS. ROI(Region of Interest) 내에서 이동 가능 영역과 중심점 추정. /center_point 토픽으로 계산된 중심점 전송.  
     
    **4. 성과 및 분석**
     
     모델 추론 결과: 이동 가능 영역, 장애물의 분할 정확도: mIoU 97% 이상. 중심점 계산의 평균 오차: ±5 픽셀.  
     제어 성능: PID 제어를 통해 ±0.1미터 내의 위치 정확도를 달성. 장애물 회피 성공률: 96%.  
     실시간 처리 능력: RGB-D 카메라 입력 처리 속도: 평균 28~30 FPS.  
     
     **테스트 결과**
     다양한 환경(좁은 통로, 복잡한 장애물 등)에서 로봇의 안정적인 자율 주행이 확인됨.  
     목표 지점 도달 후 다음 목표 요청까지의 프로세스가 성공적으로 수행됨.  
     
    **5. 결론**
     본 프로젝트는 기존 시스템의 한계를 극복하며, 농업 및 축산 환경에서 실시간 장애물 탐지 및 회피를 수행하는 모바일 로봇을 성공적으로 개발함. 이를 통해  경제적인 유지보수와 자동화된 모니터링 가능. 실시간 데이터 수집 및 정밀 축산 관리 지원.  
    
  
  
## Conclusion
  본 프로젝트에서는 농업 및 축산업 환경에 적합한 모바일 로봇 시스템을 개발하여 기존 시스템의 문제를 해결하고자 함.  
  센서 퓨전 알고리즘을 활용하여 이동체의 위치 및 상태 추정의 정확성을 높힘.  
  RGB-D 카메라와 의미론적 분할을 통해 이동 가능 영역과 장애물의 특성을 실시간으로 분석하고, 새로운 이동 경로를 생성하는 알고리즘을 구현함.  
  이러한 시스템은 육돈의 건강 관리를 개선하고 작업자의 부담을 줄이는 동시에 정밀 축산 관리의 기반을 제공합니다. 또한, 기존 CCTV 시스템의 유지보수 비용을 절감하며, 다양한 작업 환경에서 안정적으로 사용할 수 있는 자율주행 로봇 플랫폼을 구축함.  
  이를 통해 농업 및 축산업의 생산성 향상, 비용 절감, 그리고 데이터 기반 의사결정이 가능해질 것으로 기대됨.  
  
## Project Outcome
- ### 20XX 년 OO학술대회 
